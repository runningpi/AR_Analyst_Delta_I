# AR Analyst Delta I Pipeline

**Calculate the information delta (Î”I) between analyst reports and company-issued documents.**

This pipeline analyzes analyst reports to identify novel insights by comparing them against official company documents. It quantifies what information in analyst reports is truly new versus what's already disclosed by the company.

## ğŸ“Š What Does It Do?

The pipeline answers the key question: **"What novel information are analysts providing beyond official company disclosures?"**

**Formula:** `Î”I = Î”AR - Î”Î£`
- **Î”AR**: Information in Analyst Reports
- **Î”Î£**: Information in Company Documents (10-K, 10-Q, earnings calls, presentations)
- **Î”I**: The information delta - novel analyst insights

### Key Outputs

For each analyst report, the pipeline provides:
- **Coverage Analysis**: What % of analyst claims are supported by company documents
- **Novel Insights**: Sentences not found in company documents (potential alpha)
- **Contradictions**: Claims that contradict official company statements
- **Detailed Report**: Section-by-section analysis with evidence

## ğŸ—ï¸ Pipeline Architecture

The pipeline consists of 5 stages, each with its own caching mechanism:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. OCR & Text Extraction (Decomposition_AR)                     â”‚
â”‚    â””â”€ Extract text from PDF analyst reports using Docling       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Sentence Classification (Decomposition_AR)                   â”‚
â”‚    â””â”€ LLM categorizes sentences: corporate_info, market_info,   â”‚
â”‚       analyst_interpretation, other                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Knowledge Base Matching (RAG_and_knowledgebase)             â”‚
â”‚    â””â”€ DS-RAG queries company documents for supporting evidence  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. LLM Evaluation (Evaluation)                                  â”‚
â”‚    â””â”€ GPT-4 evaluates: Supported, Partially Supported,         â”‚
â”‚       Not Supported, Contradicted, No Evidence                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. Analysis & Reporting (Analysis)                             â”‚
â”‚    â””â”€ Generate comprehensive reports, statistics, and insights  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
Analysis_Pipeline/
â”‚
â”œâ”€â”€ ğŸ“„ Entry Points & Config
â”‚   â”œâ”€â”€ analyse_delta_i_for_one_AR.py    # Main entry point
â”‚   â”œâ”€â”€ config.py                        # Configuration loader
â”‚   â”œâ”€â”€ settings.config                  # Pipeline settings
â”‚   â””â”€â”€ requirements.txt                 # Dependencies
â”‚
â”œâ”€â”€ ğŸ¯ core/                             # Orchestration & Data Models
â”‚   â”œâ”€â”€ pipeline.py                      # Main pipeline orchestrator
â”‚   â”œâ”€â”€ analysis.py                      # Analysis & reporting utilities
â”‚   â””â”€â”€ models/                          # Data models (Pydantic)
â”‚       â”œâ”€â”€ sentence.py
â”‚       â”œâ”€â”€ evaluation.py
â”‚       â””â”€â”€ section.py
â”‚
â”œâ”€â”€ ğŸ“Š Pipeline Stages
â”‚   â”œâ”€â”€ Decomposition_AR/                # Stage 1 & 2: OCR & Classification
â”‚   â”‚   â”œâ”€â”€ ocr_docling_utils.py
â”‚   â”‚   â”œâ”€â”€ classification_service.py
â”‚   â”‚   â”œâ”€â”€ text_mangement_utils.py
â”‚   â”‚   â”œâ”€â”€ ocr_content/[PDF_NAME]/      # ğŸ“¦ Cached OCR outputs
â”‚   â”‚   â””â”€â”€ output/classified_sentences/[PDF_NAME]/  # ğŸ“¦ Cached classifications
â”‚   â”‚
â”‚   â”œâ”€â”€ RAG_and_knowledgebase/           # Stage 3: KB Matching
â”‚   â”‚   â”œâ”€â”€ DS_RAG_utils.py
â”‚   â”‚   â”œâ”€â”€ matching_utils.py
â”‚   â”‚   â”œâ”€â”€ kb_storage/                  # Knowledge base vector storage
â”‚   â”‚   â””â”€â”€ output/[PDF_NAME]/           # ğŸ“¦ Cached query results
â”‚   â”‚
â”‚   â”œâ”€â”€ Evaluation/                      # Stage 4: LLM Evaluation
â”‚   â”‚   â”œâ”€â”€ evaluation_service.py
â”‚   â”‚   â”œâ”€â”€ evaluation_utils.py
â”‚   â”‚   â””â”€â”€ output/[PDF_NAME]/           # ğŸ“¦ Cached evaluations
â”‚   â”‚
â”‚   â””â”€â”€ Analysis/                        # Stage 5: Final Reports
â”‚       â””â”€â”€ output/[PDF_NAME]/           # ğŸ“¦ Final analysis reports
â”‚
â””â”€â”€ ğŸ“ data/                             # Input data
    â””â”€â”€ [COMPANY]/[QUARTER]/
        â”œâ”€â”€ analyst_report/              # Analyst reports (PDFs)
        â””â”€â”€ company_reports/             # Company documents (PDFs)
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

Create a `.env` file with your API keys:

```bash
cp env_template.txt .env
```

Edit `.env`:
```ini
OPENAI_API_KEY=your_openai_key_here
COHERE_API_KEY=your_cohere_key_here  # Optional, for reranking
```

Edit `settings.config` to point to your data:
```ini
env_file=.env
analyst_report=data/COMPANY/QUARTER/analyst_report/report.pdf
company_data_dir=data/COMPANY/QUARTER/company_reports
```

### 3. Run the Pipeline

```bash
python analyse_delta_i_for_one_AR.py
```

**That's it!** The pipeline will:
1. Extract text from the analyst report (cached after first run)
2. Classify sentences (cached after first run)
3. Build/load knowledge base from company documents
4. Match sentences against KB (cached after first run)
5. Evaluate with LLM (cached after first run)
6. Generate final analysis reports

## ğŸ“‹ Usage Examples

### Basic Usage

```bash
# Run full pipeline
python analyse_delta_i_for_one_AR.py

# With custom config
python analyse_delta_i_for_one_AR.py --config my_settings.config

# Set log level
python analyse_delta_i_for_one_AR.py --log-level DEBUG
```

### Resume from Checkpoint

Skip completed stages to save time:

```bash
# Resume from classification (skip OCR)
python analyse_delta_i_for_one_AR.py --checkpoint classified

# Resume from matching (skip OCR & classification)
python analyse_delta_i_for_one_AR.py --checkpoint matched

# Resume from evaluation (skip all except final analysis)
python analyse_delta_i_for_one_AR.py --checkpoint evaluated
```

## ğŸ’¾ Caching System

The pipeline implements **5-layer intelligent caching** to avoid redundant processing and API calls:

| Stage | Cache Location | Benefit |
|-------|---------------|---------|
| **OCR** | `Decomposition_AR/ocr_content/[PDF]/` | Skip PDF processing (~30s) |
| **Classification** | `Decomposition_AR/output/classified_sentences/[PDF]/` | Skip LLM classification calls |
| **KB Matching** | `RAG_and_knowledgebase/output/[PDF]/` | Skip vector DB queries |
| **Evaluation** | `Evaluation/output/[PDF]/` | Skip LLM evaluation calls (~$0.50) |
| **KB Storage** | `RAG_and_knowledgebase/kb_storage/` | Reuse indexed company documents |

**Performance Impact:**
- **First run**: ~3-5 minutes (includes OCR, LLM calls, KB building)

**Cache Management:**

```bash
# Clear cache for a specific document
rm -rf */output/02_01_2023_Rosenblatt/
rm -rf Decomposition_AR/ocr_content/02_01_2023_Rosenblatt/

# Clear all caches (force fresh analysis)
rm -rf */output/*/
rm -rf Decomposition_AR/ocr_content/*/

# Rebuild knowledge base
rm -rf RAG_and_knowledgebase/kb_storage/
```

## ğŸ“Š Output Files

All outputs are organized by document name in stage-specific directories:

### Final Reports (`Analysis/output/[PDF_NAME]/`)
- **`analysis_report.txt`**: Human-readable comprehensive report
- **`statistics.json`**: Detailed statistics and metrics
- **`coverage_summary.json`**: Coverage percentages and breakdowns
- **`metadata.json`**: Analysis timestamp and info

### Example Output

```
Total Sentences: 151
Covered: 42 (27.8%)          â† Supported by company documents
Not Covered: 107 (70.9%)     â† Novel analyst insights! (Î”I)
Contradicted: 2 (1.3%)       â† Contradicts company statements
```

**Interpretation:**
- 70.9% of analyst claims are NOT found in company documents = **high information delta**
- These are potential novel insights that analysts are contributing

## âš™ï¸ Configuration Options

### settings.config

```ini
env_file=.env
analyst_report=data/AMD_2022_Q4/analyst_report/report.pdf
company_data_dir=data/AMD_2022_Q4/company_reports
```

### config.py (Advanced)

You can modify `config.py` to adjust:
- **Models**: `classification_model`, `evaluation_model`, `embedding_model`
- **Batch sizes**: `classification_batch_size`
- **Retrieval**: `top_k_results`, `chunk_size`
- **DS-RAG**: `use_semantic_sectioning`

## ğŸ”¬ Technical Details

### Models Used

- **Classification**: GPT-4o-mini (categorizes sentences)
- **Evaluation**: GPT-4o-mini (assesses evidence support)
- **Embeddings**: OpenAI text-embedding-3-small (via DS-RAG)
- **Reranking**: Cohere Rerank (optional, improves retrieval)

### DS-RAG Integration

The pipeline uses [DS-RAG](https://github.com/D-Star-AI/dsRAG) for advanced RAG capabilities:
- **Content-Driven Chunking**: Intelligent document segmentation
- **AutoContext**: LLM-generated context for each chunk
- **Semantic Search**: Vector similarity + keyword matching
- **Reranking**: Optional Cohere reranking for better results

### Evaluation Labels

| Label | Description |
|-------|-------------|
| **Supported** | Evidence fully backs the claim |
| **Partially Supported** | Evidence partially backs the claim |
| **Not Supported** | No supporting evidence found |
| **Contradicted** | Evidence directly contradicts the claim |
| **No Evidence** | No relevant evidence in knowledge base |

## ğŸ› Troubleshooting

### Common Issues

**1. CUDA Compatibility Error**
```python
# The pipeline automatically forces CPU for OCR
# No action needed - it's handled internally
```

**2. API Key Errors**
```bash
# Check your .env file
cat .env

# Ensure keys are set
echo $OPENAI_API_KEY
```

**3. Out of Memory**
```python
# Reduce batch size in config.py
classification_batch_size = 5  # Default: 10
```

**4. Cohere Rate Limits**
```
# Cohere trial keys have limits
# Either upgrade to production key or disable reranking
# Reranking is optional - pipeline works without it
```

## ğŸ“š Key Dependencies

- **docling** >= 1.0.0 - PDF OCR and text extraction
- **dsrag** - Advanced RAG framework
- **openai** - LLM classification and evaluation
- **cohere** (optional) - Reranking for better retrieval
- **pydantic** - Data validation and models

## ğŸ¤ Contributing

This is an internal research pipeline. For questions or issues, contact the DataNXT team.

## ğŸ“„ License

Internal use only - Goethe University Research

---

## ğŸ¯ Example Workflow

```bash
# 1. Setup
cd Analysis_Pipeline
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# 2. Configure
cp env_template.txt .env
# Edit .env with your API keys
# Edit settings.config with your data paths

# 3. Run
python analyse_delta_i_for_one_AR.py

# 4. Review results
cat Analysis/output/02_01_2023_Rosenblatt/analysis_report.txt
```

## ğŸ“ˆ Performance Benchmarks

**Test Case**: AMD Q4 2022 Analyst Report
- Document: 8 pages, 151 sentences
- Company KB: 6 documents (10-Qs, 10-K, earnings call, presentation)

| Stage | First Run | Cached Run | API Calls |
|-------|-----------|------------|-----------|
| OCR | 30s | 0.01s | 0 |
| Classification | 45s | 0.01s | 15 â†’ 0 |
| KB Matching | 60s | 0.01s | 151 â†’ 0 |
| Evaluation | 90s | 0.01s | 151 â†’ 0 |
| Analysis | 0.5s | 0.5s | 0 |
| **TOTAL** | **~3.5 min** | **~0.2s** | **317 â†’ 0** |

**Cost Savings**: ~$0.75 per cached run

---

**Built with â¤ï¸ by the ManÃº Weissel**

